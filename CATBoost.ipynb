{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XowC7KjhhNln",
        "outputId": "b3225890-220a-4f2c-804d-a9c39eaf5ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mycUzUWimlno",
        "outputId": "c64bf1f8-48c0-413c-9220-462b66c9ccce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_paDf3hr5wh",
        "outputId": "aefa3379-6a0b-4863-94f1-aea702305186"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.16.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from category_encoders import TargetEncoder"
      ],
      "metadata": {
        "id": "JSUOHtbuwvf0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values\n",
        "for col in ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']:\n",
        "    train_data[col] = train_data[col].fillna(train_data[col].mean())\n",
        "    test_data[col] = test_data[col].fillna(test_data[col].mean())"
      ],
      "metadata": {
        "id": "3M0NiOuGwyNr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical columns to strings and fill NaN\n",
        "for col in ['CryoSleep', 'VIP', 'HomePlanet', 'Destination']:\n",
        "    train_data[col] = train_data[col].astype(str).fillna('Unknown')\n",
        "    test_data[col] = test_data[col].astype(str).fillna('Unknown')\n",
        "\n",
        "train_data['Cabin'] = train_data['Cabin'].astype(str).fillna('Unknown/0/Unknown')\n",
        "test_data['Cabin'] = test_data['Cabin'].astype(str).fillna('Unknown/0/Unknown')"
      ],
      "metadata": {
        "id": "jqgC53rew0K3"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering\n",
        "# Split Cabin into Deck, Num, and Side\n",
        "train_data[['Deck', 'Num', 'Side']] = train_data['Cabin'].str.split('/', expand=True)\n",
        "test_data[['Deck', 'Num', 'Side']] = test_data['Cabin'].str.split('/', expand=True)\n",
        "train_data['Num'] = pd.to_numeric(train_data['Num'], errors='coerce').fillna(0).astype(int)\n",
        "test_data['Num'] = pd.to_numeric(test_data['Num'], errors='coerce').fillna(0).astype(int)\n",
        "train_data['Deck'] = train_data['Deck'].fillna('Unknown')\n",
        "train_data['Side'] = train_data['Side'].fillna('Unknown')\n",
        "test_data['Deck'] = test_data['Deck'].fillna('Unknown')\n",
        "test_data['Side'] = test_data['Side'].fillna('Unknown')"
      ],
      "metadata": {
        "id": "c9vQxVKSw1hx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract family size from Name\n",
        "train_data['Surname'] = train_data['Name'].str.split().str[-1].fillna('Unknown')\n",
        "test_data['Surname'] = test_data['Name'].str.split().str[-1].fillna('Unknown')\n",
        "train_data['FamilySize'] = train_data.groupby('Surname')['PassengerId'].transform('count')\n",
        "test_data['FamilySize'] = test_data.groupby('Surname')['PassengerId'].transform('count')\n",
        "train_data['FamilySize'] = train_data['FamilySize'].fillna(1)\n",
        "test_data['FamilySize'] = test_data['FamilySize'].fillna(1)"
      ],
      "metadata": {
        "id": "6dyDfc0ww3Jv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate TotalSpend and new features\n",
        "train_data['TotalSpend'] = train_data[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
        "test_data['TotalSpend'] = test_data[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
        "train_data['CryoSleep_Binary'] = train_data['CryoSleep'].map({'True': 1, 'False': 0, 'Unknown': 0}).fillna(0).astype(int)\n",
        "test_data['CryoSleep_Binary'] = test_data['CryoSleep'].map({'True': 1, 'False': 0, 'Unknown': 0}).fillna(0).astype(int)\n",
        "train_data['CryoSpendInteraction'] = train_data['CryoSleep_Binary'] * train_data['TotalSpend']\n",
        "test_data['CryoSpendInteraction'] = test_data['CryoSleep_Binary'] * test_data['TotalSpend']"
      ],
      "metadata": {
        "id": "UBWtDQGCw4eK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Polynomial features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "poly_features = ['Age', 'TotalSpend', 'Num']\n",
        "poly_train = poly.fit_transform(train_data[poly_features])\n",
        "poly_test = poly.transform(test_data[poly_features])\n",
        "poly_columns = [f'poly_{i}' for i in range(poly_train.shape[1])]\n",
        "train_data[poly_columns] = poly_train\n",
        "test_data[poly_columns] = poly_test"
      ],
      "metadata": {
        "id": "uyC5QV0gw6Nz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale numerical features\n",
        "numerical_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'TotalSpend', 'Num', 'CryoSpendInteraction', 'FamilySize', 'CryoSleep_Binary'] + poly_columns\n",
        "scaler = StandardScaler()\n",
        "train_data[numerical_features] = scaler.fit_transform(train_data[numerical_features])\n",
        "test_data[numerical_features] = scaler.transform(test_data[numerical_features])\n"
      ],
      "metadata": {
        "id": "HiaqwQykw79N"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare features and target\n",
        "categorical_features = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side', 'Surname']\n",
        "X_train = train_data.drop(columns=['PassengerId', 'Name', 'Transported', 'Cabin'])\n",
        "y_train = train_data['Transported'].astype(int)\n",
        "X_test = test_data.drop(columns=['PassengerId', 'Name', 'Cabin'])"
      ],
      "metadata": {
        "id": "oL0E1lCmw92N"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class imbalance\n",
        "print(\"Class distribution:\", y_train.value_counts())\n",
        "class_counts = y_train.value_counts()\n",
        "class_weight_0 = class_counts[1] / len(y_train)\n",
        "class_weight_1 = class_counts[0] / len(y_train)\n",
        "class_weights = {0: class_weight_0 * 1.5, 1: class_weight_1 * 1.5}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv6UBMaUw_-8",
        "outputId": "0ec19d72-4b8a-4359-95e0-0c7a531a5bda"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution: Transported\n",
            "1    4378\n",
            "0    4315\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Target encoding with manual cross-validation\n",
        "encoder = TargetEncoder(cols=categorical_features)\n",
        "# Initialize encoded DataFrames with numerical columns only\n",
        "X_train_encoded = pd.DataFrame(train_data[numerical_features].copy(), columns=numerical_features)\n",
        "X_test_encoded = pd.DataFrame(test_data[numerical_features].copy(), columns=numerical_features)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for train_idx, val_idx in skf.split(X_train, y_train):\n",
        "    X_train_fold = X_train.iloc[train_idx]\n",
        "    y_train_fold = y_train.iloc[train_idx]\n",
        "    X_val_fold = X_train.iloc[val_idx]\n",
        "    encoder.fit(X_train_fold[categorical_features], y_train_fold)\n",
        "    encoded_vals = encoder.transform(X_val_fold[categorical_features])\n",
        "    # Assign encoded values to the validation indices\n",
        "    for col in categorical_features:\n",
        "        X_train_encoded.loc[val_idx, col] = encoded_vals[col].values\n",
        "encoder.fit(X_train[categorical_features], y_train)  # Fit on full train for test\n",
        "X_test_encoded[categorical_features] = encoder.transform(X_test[categorical_features])\n"
      ],
      "metadata": {
        "id": "93QfHo9pxC0U"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all encoded columns are float\n",
        "for col in categorical_features:\n",
        "    X_train_encoded[col] = X_train_encoded[col].astype(float)\n",
        "    X_test_encoded[col] = X_test_encoded[col].astype(float)\n",
        "\n",
        "# Combine encoded and numerical features (already combined in initialization)\n",
        "X_train_final = X_train_encoded\n",
        "X_test_final = X_test_encoded"
      ],
      "metadata": {
        "id": "RDGu_tOFxEuu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation and model training\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "test_preds = np.zeros(len(test_data))\n",
        "models = []\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.15],  # Slightly broadened\n",
        "    'depth': [3, 4, 5],\n",
        "    'l2_leaf_reg': [5, 10, 15]\n",
        "}\n",
        "\n",
        "best_score = 0\n",
        "best_params = None\n",
        "for lr in param_grid['learning_rate']:\n",
        "    for d in param_grid['depth']:\n",
        "        for l2 in param_grid['l2_leaf_reg']:\n",
        "            model = CatBoostClassifier(\n",
        "                iterations=500,\n",
        "                learning_rate=lr,\n",
        "                depth=d,\n",
        "                l2_leaf_reg=l2,\n",
        "                eval_metric='Accuracy',\n",
        "                early_stopping_rounds=30,\n",
        "                verbose=0,\n",
        "                class_weights=class_weights\n",
        "            )\n",
        "            cv_scores = []\n",
        "            for train_idx, val_idx in skf.split(X_train_final, y_train):\n",
        "                X_train_fold = X_train_final.iloc[train_idx]\n",
        "                y_train_fold = y_train.iloc[train_idx]\n",
        "                X_val_fold = X_train_final.iloc[val_idx]\n",
        "                y_val_fold = y_train.iloc[val_idx]\n",
        "                model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], verbose=0)\n",
        "                val_preds = model.predict_proba(X_val_fold)[:, 1]\n",
        "                val_preds = (val_preds > 0.5).astype(int)\n",
        "                cv_scores.append((val_preds == y_val_fold).mean())\n",
        "            mean_cv_score = np.mean(cv_scores)\n",
        "            if mean_cv_score > best_score:\n",
        "                best_score = mean_cv_score\n",
        "                best_params = {'learning_rate': lr, 'depth': d, 'l2_leaf_reg': l2}\n",
        "\n",
        "print(f\"Best CV Score: {best_score:.4f} with params: {best_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlMSgejSwsro",
        "outputId": "4f7efb47-fef8-4ce5-e046-c2ffce47fd3f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best CV Score: 0.8120 with params: {'learning_rate': 0.15, 'depth': 5, 'l2_leaf_reg': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train final model with best parameters and log feature importance\n",
        "best_model = CatBoostClassifier(\n",
        "    iterations=500,\n",
        "    learning_rate=best_params['learning_rate'],\n",
        "    depth=best_params['depth'],\n",
        "    l2_leaf_reg=best_params['l2_leaf_reg'],\n",
        "    eval_metric='Accuracy',\n",
        "    early_stopping_rounds=30,\n",
        "    verbose=0,\n",
        "    class_weights=class_weights\n",
        ")"
      ],
      "metadata": {
        "id": "arpmbQ1qxM31"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit on full training data to get feature importance\n",
        "best_model.fit(X_train_final, y_train)\n",
        "feature_importance = best_model.get_feature_importance()\n",
        "feature_names = X_train_final.columns\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
        "print(\"Feature Importance:\\n\", importance_df.sort_values(by='Importance', ascending=False))\n",
        "\n",
        "for train_idx, val_idx in skf.split(X_train_final, y_train):\n",
        "    X_train_fold = X_train_final.iloc[train_idx]\n",
        "    y_train_fold = y_train.iloc[train_idx]\n",
        "    X_val_fold = X_train_final.iloc[val_idx]\n",
        "    y_val_fold = y_train.iloc[val_idx]\n",
        "    best_model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], verbose=0)\n",
        "    models.append(best_model)\n",
        "    test_preds += best_model.predict_proba(X_test_final)[:, 1] / n_splits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAQswaxLxPg1",
        "outputId": "2b742955-7cad-4c9b-859a-dc993ca95499"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance:\n",
            "                  Feature  Importance\n",
            "24                  Deck    9.296289\n",
            "20            HomePlanet    9.160655\n",
            "4                    Spa    6.930574\n",
            "12                poly_1    6.439589\n",
            "5                 VRDeck    6.368154\n",
            "2              FoodCourt    6.073270\n",
            "26               Surname    4.931209\n",
            "25                  Side    4.508336\n",
            "7                    Num    4.447268\n",
            "1            RoomService    3.855540\n",
            "18                poly_7    3.546942\n",
            "3           ShoppingMall    3.527178\n",
            "17                poly_6    2.919483\n",
            "14                poly_3    2.918155\n",
            "22           Destination    2.851151\n",
            "16                poly_5    2.850233\n",
            "10      CryoSleep_Binary    2.841244\n",
            "15                poly_4    2.698337\n",
            "13                poly_2    2.354907\n",
            "9             FamilySize    1.961645\n",
            "19                poly_8    1.847215\n",
            "21             CryoSleep    1.770067\n",
            "8   CryoSpendInteraction    1.508348\n",
            "6             TotalSpend    1.312818\n",
            "11                poly_0    1.156212\n",
            "0                    Age    1.094016\n",
            "23                   VIP    0.831168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test a refined threshold range\n",
        "thresholds = [0.45, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53]\n",
        "best_score = 0\n",
        "best_predictions = None\n",
        "\n",
        "for thresh in thresholds:\n",
        "    predictions = (test_preds > thresh).astype(int)\n",
        "    submission = pd.DataFrame({\n",
        "        'PassengerId': test_data['PassengerId'],\n",
        "        'Transported': predictions.astype(bool)\n",
        "    })\n",
        "    # Simulate score using CV accuracy\n",
        "    cv_scores = []\n",
        "    for i, (train_idx, val_idx) in enumerate(skf.split(X_train_final, y_train)):\n",
        "        X_train_fold = X_train_final.iloc[train_idx]\n",
        "        y_train_fold = y_train.iloc[train_idx]\n",
        "        X_val_fold = X_train_final.iloc[val_idx]\n",
        "        y_val_fold = y_train.iloc[val_idx]\n",
        "        val_preds = models[i].predict_proba(X_val_fold)[:, 1]\n",
        "        val_preds = (val_preds > thresh).astype(int)\n",
        "        cv_scores.append((val_preds == y_val_fold).mean())\n",
        "    mean_cv_score = np.mean(cv_scores)\n",
        "    print(f\"Threshold {thresh}: CV Accuracy = {mean_cv_score:.4f}\")\n",
        "    if mean_cv_score > best_score:\n",
        "        best_score = mean_cv_score\n",
        "        best_predictions = predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ykvqc_7rxR99",
        "outputId": "3845a3e6-c68f-4dd0-835d-8e14a2a4bab8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold 0.45: CV Accuracy = 0.8574\n",
            "Threshold 0.47: CV Accuracy = 0.8582\n",
            "Threshold 0.48: CV Accuracy = 0.8594\n",
            "Threshold 0.49: CV Accuracy = 0.8595\n",
            "Threshold 0.5: CV Accuracy = 0.8614\n",
            "Threshold 0.51: CV Accuracy = 0.8605\n",
            "Threshold 0.52: CV Accuracy = 0.8591\n",
            "Threshold 0.53: CV Accuracy = 0.8602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the best predictions\n",
        "submission = pd.DataFrame({\n",
        "    'PassengerId': test_data['PassengerId'],\n",
        "    'Transported': best_predictions.astype(bool)\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "submission.to_csv('predictions.csv', index=False)\n",
        "\n",
        "print(f\"Best Threshold: {thresholds[np.argmax([np.mean(cv_scores) for thresh in thresholds])]}\")\n",
        "print(f\"Cross-Validation Accuracy: {best_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPGNoV6YxLiN",
        "outputId": "1b9374db-5c6a-43ac-9ad7-fa7f0a2e52fe"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold: 0.45\n",
            "Cross-Validation Accuracy: 0.8614\n"
          ]
        }
      ]
    }
  ]
}